{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16886a07",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "938be0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "# modelling for ensemble method\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa805d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197f3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "628a1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting \n",
    "X, y = df.drop(['IDNumber','diagnosis'], axis=1), df['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c699bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index dari data training dan data testing agar tidak error saat indexing\n",
    "# X_train.reset_index(drop=True, inplace=True)\n",
    "# X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# y_train.reset_index(drop=True, inplace=True)\n",
    "# y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0772a",
   "metadata": {},
   "source": [
    "# Defining Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=45, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5aa97c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891ed44",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "***\n",
    "Using Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620a3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540a829",
   "metadata": {},
   "source": [
    "## Label Encoding Target\n",
    "***\n",
    "Convert B --> 0 and M --> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd9f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59549e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.to_numpy()\n",
    "# X_test = X_test.to_numpy()\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a9ea9",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9d439",
   "metadata": {},
   "source": [
    "## Create Stacking ML Ensemble from 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cddaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classifiers = {\n",
    "    'svm' : dict(),\n",
    "    'logreg': dict(),\n",
    "    'naive_bayes': dict(),\n",
    "    'decision_tree': dict()\n",
    "}\n",
    "\n",
    "for idx, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "    \n",
    "    # split training set into train and val set\n",
    "    X_latih, X_validasi = X_train[train_index], X_train[val_index]\n",
    "    y_latih, y_validasi = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # train 5 model of SVM\n",
    "    svm = SVC()\n",
    "    svm.fit(X_latih, y_latih)\n",
    "    predicted_svm = svm.predict(X_validasi)\n",
    "    \n",
    "    ensemble_classifiers['svm']['model-'+str(idx+1)] = {\n",
    "        'train':svm,\n",
    "        'validation': accuracy_score(y_validasi, predicted_svm)\n",
    "    }\n",
    "    \n",
    "    # train 5 model of logReg\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_latih, y_latih)\n",
    "    predicted_log_reg = log_reg.predict(X_validasi)\n",
    "    \n",
    "    ensemble_classifiers['logreg']['model-'+str(idx+1)] = {\n",
    "        'train':log_reg,\n",
    "        'validation': accuracy_score(y_validasi, predicted_log_reg)\n",
    "    }\n",
    "    \n",
    "    # train 5 model of Naive Bayes\n",
    "    naive_bayes = MultinomialNB()\n",
    "    naive_bayes.fit(X_latih, y_latih)\n",
    "    predicted_naive_bayes = naive_bayes.predict(X_validasi)\n",
    "    \n",
    "    ensemble_classifiers['naive_bayes']['model-'+str(idx+1)] = {\n",
    "        'train':naive_bayes,\n",
    "        'validation': accuracy_score(y_validasi, predicted_naive_bayes)\n",
    "    }\n",
    "    \n",
    "    # train 5 model of Decision Tree\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_latih, y_latih)\n",
    "    predicted_decision_tree = decision_tree.predict(X_validasi)\n",
    "    \n",
    "    ensemble_classifiers['decision_tree']['model-'+str(idx+1)] = {\n",
    "        'train':decision_tree,\n",
    "        'validation': accuracy_score(y_validasi, predicted_decision_tree)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced8acb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': {'model-1': {'train': SVC(), 'validation': 0.975},\n",
       "  'model-2': {'train': SVC(), 'validation': 0.975},\n",
       "  'model-3': {'train': SVC(), 'validation': 0.95},\n",
       "  'model-4': {'train': SVC(), 'validation': 0.9620253164556962},\n",
       "  'model-5': {'train': SVC(), 'validation': 0.9873417721518988}},\n",
       " 'logreg': {'model-1': {'train': LogisticRegression(), 'validation': 0.95},\n",
       "  'model-2': {'train': LogisticRegression(), 'validation': 0.95},\n",
       "  'model-3': {'train': LogisticRegression(), 'validation': 0.9375},\n",
       "  'model-4': {'train': LogisticRegression(), 'validation': 0.9620253164556962},\n",
       "  'model-5': {'train': LogisticRegression(), 'validation': 1.0}},\n",
       " 'naive_bayes': {'model-1': {'train': MultinomialNB(), 'validation': 0.875},\n",
       "  'model-2': {'train': MultinomialNB(), 'validation': 0.8125},\n",
       "  'model-3': {'train': MultinomialNB(), 'validation': 0.875},\n",
       "  'model-4': {'train': MultinomialNB(), 'validation': 0.8354430379746836},\n",
       "  'model-5': {'train': MultinomialNB(), 'validation': 0.7721518987341772}},\n",
       " 'decision_tree': {'model-1': {'train': DecisionTreeClassifier(),\n",
       "   'validation': 0.9125},\n",
       "  'model-2': {'train': DecisionTreeClassifier(), 'validation': 0.875},\n",
       "  'model-3': {'train': DecisionTreeClassifier(), 'validation': 0.9125},\n",
       "  'model-4': {'train': DecisionTreeClassifier(),\n",
       "   'validation': 0.9113924050632911},\n",
       "  'model-5': {'train': DecisionTreeClassifier(),\n",
       "   'validation': 0.9493670886075949}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b5655",
   "metadata": {},
   "source": [
    "## Training the stacking ensemble ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bff23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t SVM\n",
      "\t\t Training Model SVM using model-1\n",
      "\t\t Training Model SVM using model-2\n",
      "\t\t Training Model SVM using model-3\n",
      "\t\t Training Model SVM using model-4\n",
      "\t\t Training Model SVM using model-5\n",
      "\t\t\t LOGREG\n",
      "\t\t Training Model LOGREG using model-1\n",
      "\t\t Training Model LOGREG using model-2\n",
      "\t\t Training Model LOGREG using model-3\n",
      "\t\t Training Model LOGREG using model-4\n",
      "\t\t Training Model LOGREG using model-5\n",
      "\t\t\t NAIVE_BAYES\n",
      "\t\t Training Model NAIVE_BAYES using model-1\n",
      "\t\t Training Model NAIVE_BAYES using model-2\n",
      "\t\t Training Model NAIVE_BAYES using model-3\n",
      "\t\t Training Model NAIVE_BAYES using model-4\n",
      "\t\t Training Model NAIVE_BAYES using model-5\n",
      "\t\t\t DECISION_TREE\n",
      "\t\t Training Model DECISION_TREE using model-1\n",
      "\t\t Training Model DECISION_TREE using model-2\n",
      "\t\t Training Model DECISION_TREE using model-3\n",
      "\t\t Training Model DECISION_TREE using model-4\n",
      "\t\t Training Model DECISION_TREE using model-5\n"
     ]
    }
   ],
   "source": [
    "all_predicted_results = dict()\n",
    "list_of_majority_voting_each_models = list()\n",
    "\n",
    "for model_name, models in ensemble_classifiers.items():\n",
    "    print(\"\\t\\t\\t\", model_name.upper())\n",
    "    \n",
    "    # voting scenario for data training input prepration for ANN model\n",
    "    if len(models)!=0:\n",
    "        all_predicted_results[model_name] = dict()\n",
    "        for sub_model_name, dict_models in models.items():\n",
    "            print('\\t\\t Training Model {} using {}'.format(model_name.upper(), sub_model_name))\n",
    "            all_predicted_results[model_name][sub_model_name] = dict_models['train'].predict(X_train)\n",
    "        \n",
    "        # make dataframe for 5 model prediction results on X_train and get the mode label for that 5 prediction\n",
    "        model_df_voting = pd.DataFrame(all_predicted_results[model_name]).mode(axis=1)\n",
    "        model_df_voting.columns = ['majority_vote_from_'+model_name]\n",
    "        list_of_majority_voting_each_models.append(model_df_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe19664",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input_training_features = pd.concat(list_of_majority_voting_each_models, axis=1)\n",
    "new_input_training_features['ground_truth'] = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dee34ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>majority_vote_from_svm</th>\n",
       "      <th>majority_vote_from_logreg</th>\n",
       "      <th>majority_vote_from_naive_bayes</th>\n",
       "      <th>majority_vote_from_decision_tree</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     majority_vote_from_svm  majority_vote_from_logreg  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "..                      ...                        ...   \n",
       "393                       0                          0   \n",
       "394                       0                          0   \n",
       "395                       0                          0   \n",
       "396                       1                          1   \n",
       "397                       0                          0   \n",
       "\n",
       "     majority_vote_from_naive_bayes  majority_vote_from_decision_tree  \\\n",
       "0                                 0                                 0   \n",
       "1                                 0                                 0   \n",
       "2                                 0                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                 0                                 0   \n",
       "..                              ...                               ...   \n",
       "393                               0                                 0   \n",
       "394                               0                                 0   \n",
       "395                               0                                 0   \n",
       "396                               0                                 1   \n",
       "397                               0                                 0   \n",
       "\n",
       "     ground_truth  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "393             0  \n",
       "394             0  \n",
       "395             0  \n",
       "396             1  \n",
       "397             0  \n",
       "\n",
       "[398 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input_training_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2e0ed",
   "metadata": {},
   "source": [
    "## Feed New Input features into ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1986bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y from new_input_features before feeding to ANN\n",
    "new_X_train, new_y_train = new_input_training_features.drop(['ground_truth'],axis=1), new_input_training_features['ground_truth']\n",
    "# new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y, test_size=0.2, random_state=45)\n",
    "\n",
    "# feed new X and new y into ANN\n",
    "ann_model = MLPClassifier(max_iter=400)\n",
    "ann_model.fit(new_X_train, new_y_train)\n",
    "\n",
    "predicted_ann_train = ann_model.predict(new_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb475b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(new_y_train, predicted_ann_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df9b73",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed9c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t SVM\n",
      "\t\t Testing Model SVM using model-1\n",
      "\t\t Testing Model SVM using model-2\n",
      "\t\t Testing Model SVM using model-3\n",
      "\t\t Testing Model SVM using model-4\n",
      "\t\t Testing Model SVM using model-5\n",
      "\t\t\t LOGREG\n",
      "\t\t Testing Model LOGREG using model-1\n",
      "\t\t Testing Model LOGREG using model-2\n",
      "\t\t Testing Model LOGREG using model-3\n",
      "\t\t Testing Model LOGREG using model-4\n",
      "\t\t Testing Model LOGREG using model-5\n",
      "\t\t\t NAIVE_BAYES\n",
      "\t\t Testing Model NAIVE_BAYES using model-1\n",
      "\t\t Testing Model NAIVE_BAYES using model-2\n",
      "\t\t Testing Model NAIVE_BAYES using model-3\n",
      "\t\t Testing Model NAIVE_BAYES using model-4\n",
      "\t\t Testing Model NAIVE_BAYES using model-5\n",
      "\t\t\t DECISION_TREE\n",
      "\t\t Testing Model DECISION_TREE using model-1\n",
      "\t\t Testing Model DECISION_TREE using model-2\n",
      "\t\t Testing Model DECISION_TREE using model-3\n",
      "\t\t Testing Model DECISION_TREE using model-4\n",
      "\t\t Testing Model DECISION_TREE using model-5\n"
     ]
    }
   ],
   "source": [
    "all_predicted_results = dict()\n",
    "list_of_majority_voting_each_models = list()\n",
    "\n",
    "for model_name, models in ensemble_classifiers.items():\n",
    "    print(\"\\t\\t\\t\", model_name.upper())\n",
    "    \n",
    "    # voting scenario for data testing input prepration for ANN model\n",
    "    if len(models)!=0:\n",
    "        all_predicted_results[model_name] = dict()\n",
    "        for sub_model_name, dict_models in models.items():\n",
    "            print('\\t\\t Testing Model {} using {}'.format(model_name.upper(), sub_model_name))\n",
    "            all_predicted_results[model_name][sub_model_name] = dict_models['train'].predict(X_test)\n",
    "        \n",
    "        # make dataframe for 5 model prediction results on X_test and get the mode label for that 5 prediction\n",
    "        model_df_voting = pd.DataFrame(all_predicted_results[model_name]).mode(axis=1)\n",
    "        model_df_voting.columns = ['majority_vote_from_'+model_name]\n",
    "        list_of_majority_voting_each_models.append(model_df_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "832ba66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input_testing_features = pd.concat(list_of_majority_voting_each_models, axis=1)\n",
    "new_input_testing_features['ground_truth'] = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c4d9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y from new_input_features before feeding to ANN\n",
    "new_X_test, new_y_test = new_input_testing_features.drop(['ground_truth'],axis=1), new_input_testing_features['ground_truth']\n",
    "\n",
    "# predict new X test using pre-trained ANN before\n",
    "predicted_ann_testing = ann_model.predict(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "409fb26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       108\n",
      "           1       0.94      0.95      0.94        63\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_ann_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "170b1c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, predicted_ann_testing), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2583d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2_computational_intelligence_ensemble_daun_singkong",
   "language": "python",
   "name": "s2_computational_intelligence_ensemble_daun_singkong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
